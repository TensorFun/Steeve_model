{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from collections import Counter, defaultdict\n",
    "from functools import reduce\n",
    "import json\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank\n",
    "* Train Test Score\n",
    "* filter no_filter 0.699\n",
    "* no_filter filter 0.9227608874281019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KEYWORD_PATH = '/home/fun/Atos/Steeve_data/filter_Dice/can/'\n",
    "TEST_PATH = '/home/fun/Atos/Steeve_data/no_filter_Dice/can/'\n",
    "score_file = 'tfidf_score_filter.json'\n",
    "\n",
    "limit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls '/home/fun/Atos/Steeve_data/no_filter_Dice/can/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ########### Get all fields counter and total counter\n",
    "    index_to_field, field_to_index, fields_pl = {}, {}, []\n",
    "    for i, file in enumerate(listdir(KEYWORD_PATH)):\n",
    "        doc = json.loads(open(KEYWORD_PATH + file, 'r', encoding='utf8').read())\n",
    "        posts = sum(doc.values(), [])\n",
    "        posts = posts[:limit] if limit else posts\n",
    "        print(\"posts length: {}\".format(len(posts)))\n",
    "        \n",
    "        index_to_field[i] = file\n",
    "        field_to_index[file] = i\n",
    "        pls = [p for post in posts for p in post['PL']]\n",
    "        fields_pl.append(' '.join(pls))\n",
    "    ############\n",
    "    \n",
    "    \n",
    "    ############ Count tfidf\n",
    "    vectorizer  = CountVectorizer()  # 該類會將文本中的詞語轉換為詞頻矩陣，矩陣元素a[i][j] 表示j詞在i類文本下的詞頻  \n",
    "    transformer = TfidfTransformer() # 該類會統計每個詞語的tf-idf權值  \n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(fields_pl)) # 第一個fit_transform是計算tf-idf，第二個fit_transform是將文本轉為詞頻矩陣  \n",
    "    \n",
    "    word = vectorizer.get_feature_names() # 獲取詞袋模型中的所有詞語  \n",
    "    weight = tfidf.toarray()              # 將tf-idf矩陣抽取出來，元素a[i][j]表示j詞在i類文本中的tf-idf權重  \n",
    "    \n",
    "    tfidf_score = defaultdict(lambda: defaultdict())\n",
    "    for i in range(len(weight)):          # 打印每類文本的tf-idf詞語權重，第一個for遍歷所有文本，第二個for便利某一類文本下的詞語權重  \n",
    "        print(\"-------這裡輸出第\",i,u\"類文本的詞語tf-idf權重------\")\n",
    "        for j in range(len(word)):\n",
    "            tfidf_score[index_to_field[i]][word[j]] = weight[i][j]\n",
    "            print(word[j], weight[i][j])\n",
    "            \n",
    "    with open(score_file, 'w', encoding='utf8') as ws:\n",
    "        ws.write(json.dumps(tfidf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    correct, total = 0, 0\n",
    "    unexist = Counter()\n",
    "    for i, file in enumerate(listdir(TEST_PATH)):\n",
    "        print(file, index_to_field[i])\n",
    "        \n",
    "        doc = json.loads(open(TEST_PATH + file, 'r', encoding='utf8').read())\n",
    "        posts = [post['PL'] for post in sum(doc.values(), [])]\n",
    "\n",
    "        for post in posts:\n",
    "            fields_score = defaultdict(lambda: 0.0)\n",
    "            for pl in post:\n",
    "                pl = pl.lower()\n",
    "                if pl not in word:\n",
    "                    unexist[pl] += 1\n",
    "                    continue\n",
    "                    \n",
    "                for field, score in tfidf_score.items():\n",
    "                    fields_score[field] += score[pl]\n",
    "            \n",
    "            try:\n",
    "                index = max(fields_score.items(), key=operator.itemgetter(1))[0]\n",
    "            except:\n",
    "                print(fields_score)\n",
    "\n",
    "            if index == index_to_field[i]: \n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "    print(correct)\n",
    "    print(total)\n",
    "    print(correct / total)\n",
    "    print(unexist)\n",
    "    \n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
