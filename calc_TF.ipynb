{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from collections import Counter, defaultdict\n",
    "from functools import reduce\n",
    "import json\n",
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "from pyfasttext import FastText\n",
    "model = FastText('../wiki.en.bin')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_extraction, svm, metrics\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_file = 'tfidf_score_filter.json'\n",
    "train = 'filter_Dice'\n",
    "test = 'no_filter_Dice'\n",
    "\n",
    "TRAIN_PATH = '/home/fun/Atos/new_Steeve_data/' + train + '/can/'\n",
    "TEST_PATH = '/home/fun/Atos/new_Steeve_data/' + test + '/can/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywordsdatabase-administrator.txt  Keywordsproduct-manager.txt\r\n",
      "Keywordsjava-developer.txt          Keywordssystems-analyst.txt\r\n",
      "Keywordsnetwork-technician.txt      Keywordsweb-developer.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls '/home/fun/Atos/new_Steeve_data/CareerBuilder/can/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tfidf(doc):\n",
    "    vectorizer  = CountVectorizer(min_df=1, token_pattern=r'[\\w\\+\\.#-]+')  # 該類會將文本中的詞語轉換為詞頻矩陣，矩陣元素a[i][j] 表示j詞在i類文本下的詞頻  \n",
    "    transformer = TfidfTransformer()                                       # 該類會統計每個詞語的tf-idf權值  \n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(doc))       # 第一個fit_transform是計算tf-idf，第二個fit_transform是將文本轉為詞頻矩陣  \n",
    "    \n",
    "    words   = vectorizer.get_feature_names()                                # 獲取詞袋模型中的所有詞語  \n",
    "    weight = tfidf.toarray()                                               # 將tf-idf矩陣抽取出來，元素a[i][j]表示j詞在i類文本中的tf-idf權重  \n",
    "    \n",
    "    tfidf_score = defaultdict(lambda: defaultdict())\n",
    "    for i in range(len(weight)):                                           # 打印每類文本的tf-idf詞語權重，第一個for遍歷所有文本，第二個for便利某一類文本下的詞語權重  \n",
    "#         print(\"-------這裡輸出第\",i,u\"類文本的詞語tf-idf權重------\")\n",
    "        for j in range(len(words)):\n",
    "            tfidf_score[i][words[j]] = weight[i][j]\n",
    "#             tfidf_score[index_to_field[i]][words[j]] = weight[i][j]\n",
    "#             print(words[j], weight[i][j])\n",
    "            \n",
    "#     with open(score_file, 'w', encoding='utf8') as ws:\n",
    "#         ws.write(json.dumps(tfidf_score))\n",
    "    return tfidf_score, words\n",
    "\n",
    "def norm_pl(pl):\n",
    "    return pl.lower().replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywordsandroid.txt posts length: 433\n",
      "Keywordsbackend.txt posts length: 394\n",
      "Keywordsfrontend.txt posts length: 831\n",
      "Keywordssecurity.txt posts length: 776\n",
      "Keywordsandroid.txt posts length: 1827\n",
      "Keywordsbackend.txt posts length: 2886\n",
      "Keywordsfrontend.txt posts length: 3325\n",
      "Keywordssecurity.txt posts length: 3395\n",
      "Counter({'matlab': 87, 'conditional': 78, 'knockout.js': 55, 'swing': 44, 'vhdl': 43, 'jax-ws': 41, 'gwt': 40, 'labview': 31, 'odata': 30, 'episerver': 30, 'msbuild': 28, 'comscore': 27, 'xpath': 26, 'jaxb': 26, 'silverstripe': 26, 'dynatrace': 25, 'plsql': 24, 'blade': 21, 'tensorflow': 20, 'log4j': 18, 'bugzilla': 18, 'formatting': 17, 'yaml': 17, 'nuget': 16, 'redmine': 16, 'xquery': 15, 'suse': 14, 'spring-boot': 13, 'stl': 13, 'webstorm': 13, 'mfc': 12, 'directx': 12, 'comparison': 12, 'openssl': 12, 'atlassian_jira': 12, 'cuda': 11, 'vaadin': 11, 'keras': 10, 'heap': 9, 'vsto': 9, 'react-native': 8, 'wildfly': 8, 'xamarin.ios': 8, 'cmake': 8, 'xamarin.forms': 8, 'yii2': 8, 'twilio': 8, 'lithium': 8, 'pagination': 8, 'fortran': 8, 'openx': 8, 'yii': 8, 'javafx': 7, 'webserver': 7, 'fedora': 7, 'unity3d': 7, 'adapter': 7, 'signalr': 7, 'google_charts': 7, 'notepad++': 7, 'single-sign-on': 7, 'ssms': 7, 'handlebars.js': 7, 'mips': 6, 'semantic_ui': 6, 'ios7': 6, 'moq': 6, 'tealium': 6, 'xamarin.android': 6, 'jive': 6, 'nltk': 6, 'eclipselink': 6, 'dictionary': 6, 'associations': 6, 'textures': 5, 'blob': 5, 'geometry': 5, 'freebsd': 5, 'sinatra': 5, 'eloquent': 5, 'scikit-learn': 5, 'fast_esp': 5, 'rdf': 5, 'mpi': 5, 'pdo': 5, 'cfml': 5, 'chameleon': 4, 'app-store': 4, 'dataset': 4, 'storyboard': 4, 'http_server': 4, 'admob': 4, 'pyspark': 4, 'commerce_server': 4, 'mono': 4, 'c++11': 4, 'matplotlib': 4, 'cypher': 4, 'angular-cli': 4, 'ninject': 4, 'webgui': 4, 'google_web_toolkit': 4, 'sails.js': 4, 'apache_wicket': 4, 'lisp': 4, 'sbt': 4, 'locale': 3, 'dll': 3, 'store_systems': 3, 'tealeaf': 3, 'owin': 3, 'bigcommerce': 3, 'sparql': 3, 'socketio': 3, 'http/2': 3, 'resharper': 3, 'ms-access': 3, 'phpstorm': 3, 'installer': 3, 'llvm': 2, 'png': 2, 'ibm_http_server': 2, 'clang': 2, 'shader': 2, 'core-data': 2, 'dhtmlx': 2, 'mod_perl': 2, 'spree': 2, 'dtg': 2, 'ibm_websphere_commerce': 2, 'oracle_commerce': 2, 'java-8': 2, 'data-structures': 2, 'sencha-touch': 2, 'constructor': 2, 'iterator': 2, 'highstock': 2, 'sapui5': 2, 'alamofire': 2, 'concatenation': 2, 'zepto': 2, 'javaserver_pages': 2, 'ocaml': 2, 'http-server': 2, 'apache-camel': 2, 'apache-spark': 2, 'ms-office': 2, 'resin': 2, 'rubygems': 2, 'ramda': 2, 'spring-data': 2, 'phpmyadmin': 2, 'pug': 2, 'asp.net-ajax': 2, 'october_cms': 2, 'webtrends': 2, 'servicestack': 2, 'makefile': 2, 'gem': 2, 'jboss_web': 2, 'backdrop': 2, 'octave': 2, 'rss': 2, 'virtuoso': 2, 'amber': 2, 'uiwebview': 1, 'fft': 1, 'opencart': 1, 'quantcast': 1, 'kissmetrics': 1, 'doxygen': 1, 'namespaces': 1, 'avfoundation': 1, 'itunesconnect': 1, 'twiki': 1, 'ipb': 1, 'xna': 1, 'taiga': 1, 'liveperson': 1, 'docker-compose': 1, 'spring-mvc': 1, 'time-series': 1, 'jinja2': 1, 'edgecast': 1, 'hql': 1, 'sequelize.js': 1, 'deep-learning': 1, 'apache_hbase': 1, 'revel': 1, 'afnetworking': 1, 'uwp': 1, 'mailchimp': 1, 'struts2': 1, 'hippo': 1, 'cowboy': 1, 'httpclient': 1, 'duplicates': 1, 'stored-procedures': 1, 'applet': 1, 'datatable': 1, 'wamp': 1, 'sqlite3': 1, 'itext': 1, 'fastly': 1, 'chartbeat': 1, 'sailsjs': 1, 'semantic-ui': 1, 'sizmek': 1, 'redirect': 1, 'gruntjs': 1, 'jqgrid': 1, 'ibm_websphere_portal': 1, 'awt': 1, 'trac': 1, 'jpeg': 1, 'continuous-integration': 1, 'richfaces': 1, 'materialize_css': 1, 'racket': 1, 'uri': 1, 'timer': 1, 'js_charts': 1, 'oscommerce': 1, 'hhvm': 1, 'oracle_application_server': 1, 'webs': 1, 'openresty': 1, 'cygwin': 1, 'operating-system': 1, 'ibm_tivoli_storage_manager': 1, 'vignette': 1})\n",
      "0.705501618123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.60      0.71      1827\n",
      "          1       0.51      0.64      0.57      2886\n",
      "          2       0.65      0.58      0.61      3325\n",
      "          3       0.90      0.95      0.92      3395\n",
      "\n",
      "avg / total       0.72      0.71      0.71     11433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_data(directory, limit=None):\n",
    "    X, y, index_to_field, field_to_index = [], [], {}, {}\n",
    "    for i, file in enumerate(listdir(directory)):\n",
    "        if file.startswith(\".\"): continue\n",
    "            \n",
    "        doc = json.loads(open(directory + file, 'r', encoding='utf8').read())\n",
    "        posts = sum(doc.values(), [])\n",
    "        posts = posts[:limit] if limit else posts\n",
    "        print(file, \"posts length: {}\".format(len(posts)))\n",
    "        \n",
    "        index_to_field[i], field_to_index[file] = file, i\n",
    "        for post in posts:\n",
    "            X.append([norm_pl(p) for p in post['PL']])\n",
    "            y.append(i)\n",
    "    return X, y, index_to_field, field_to_index\n",
    "\n",
    "def get_doc(X, y): # for tfidf\n",
    "    doc = defaultdict(lambda: [])\n",
    "    for pls, field in zip(X, y):\n",
    "        doc[field] += pls\n",
    "    \n",
    "    doc = [' '.join(doc[i]) for i in range(len(doc))]\n",
    "    return doc\n",
    "        \n",
    "def tfidf_predict(test_X):\n",
    "    _y, unexist = [], Counter()\n",
    "    for i, post in enumerate(test_X):\n",
    "        _y.append(get_possible_field(post, unexist))\n",
    "    print(unexist)\n",
    "    return _y\n",
    "\n",
    "def get_possible_field(post, unexist=Counter()):\n",
    "    scores = defaultdict(lambda: 0.0)\n",
    "    for pl in post:\n",
    "        pl = norm_pl(pl)\n",
    "        if pl not in words:\n",
    "            unexist[pl] += 1\n",
    "            continue\n",
    "                \n",
    "        for field, score_table in tfidf_score.items():\n",
    "            scores[field] += score_table[pl]\n",
    "                \n",
    "    try:\n",
    "        index = max(scores.items(), key=operator.itemgetter(1))[0]\n",
    "        return index\n",
    "    except:\n",
    "        return 0 # 隨機猜\n",
    "    \n",
    "\n",
    "train_X, train_y, index_to_field, field_to_index = get_data(TRAIN_PATH)\n",
    "tfidf_score, words = get_tfidf(get_doc(train_X, train_y))\n",
    "test_X, test_y, _, _ = get_data(TEST_PATH)\n",
    "_y = tfidf_predict(test_X)\n",
    "\n",
    "print(metrics.accuracy_score(test_y, _y))\n",
    "print(metrics.classification_report(test_y, _y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywordsandroid.txt posts length: 433\n",
      "Keywordsbackend.txt posts length: 394\n",
      "Keywordsfrontend.txt posts length: 831\n",
      "Keywordssecurity.txt posts length: 776\n",
      "Keywordsandroid.txt posts length: 1827\n",
      "Keywordsbackend.txt posts length: 2886\n",
      "Keywordsfrontend.txt posts length: 3325\n",
      "Keywordssecurity.txt posts length: 3395\n",
      "0.704364558733\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.60      0.72      1827\n",
      "          1       0.50      0.66      0.57      2886\n",
      "          2       0.65      0.55      0.60      3325\n",
      "          3       0.90      0.95      0.92      3395\n",
      "\n",
      "avg / total       0.72      0.70      0.71     11433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def to_feature(X):\n",
    "    new_X = []\n",
    "    for post in X:\n",
    "        vec = np.zeros(300)\n",
    "        \n",
    "        ########## MODEL ###########\n",
    "        field = get_possible_field(post)\n",
    "        post = set(post) # unique\n",
    "        for pl in post:\n",
    "            if pl == '': continue\n",
    "            if pl not in words: continue\n",
    "            \n",
    "            vec += model.get_numpy_vector(pl) * tfidf_score[field][pl]\n",
    "        # vec / len(pls)\n",
    "        new_X.append(vec)\n",
    "    return new_X\n",
    "\n",
    "def train_and_predict(train_X, test_X, train_y, test_y):\n",
    "    # 建立 SVC 模型\n",
    "    svc = svm.SVC()\n",
    "    svc_fit = svc.fit(train_X, train_y)\n",
    "\n",
    "    # 預測\n",
    "    _y = svc.predict(test_X)\n",
    "    return _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y, index_to_field, field_to_index = get_data(TRAIN_PATH)\n",
    "tfidf_score, words = get_tfidf(get_doc(train_X, train_y))\n",
    "test_X, test_y, _, _ = get_data(TEST_PATH)\n",
    "\n",
    "train_X = to_feature(train_X)\n",
    "test_X = to_feature(test_X)\n",
    "    \n",
    "_y = train_and_predict(train_X, test_X, train_y, test_y)\n",
    "\n",
    "print(metrics.accuracy_score(test_y, _y))\n",
    "print(metrics.classification_report(test_y, _y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywordsjava-developer.txt posts length: 1299\n",
      "Keywordssystems-analyst.txt posts length: 1299\n",
      "Keywordsweb-developer.txt posts length: 1299\n",
      "Keywordsnetwork-technician.txt posts length: 1299\n",
      "Keywordsdatabase-administrator.txt posts length: 1299\n",
      "Keywordsproduct-manager.txt posts length: 1299\n",
      "Training data length: 6235, Test data length: 1559\n",
      "Counter({'robin': 5, 'sails.js': 4, 'silverstripe': 3, 'vaadin': 3, 'raphael': 3, 'telescope': 2, 'emacs': 2, 'phpstorm': 2, 'koa': 2, 'webtrends': 2, 'ipb': 2, 'javaserver_pages': 1, 'ms-access': 1, 'shiny': 1, 'apache2': 1, 'webstorm': 1, 'grouping': 1, 'accessible_portal': 1, 'activerecord': 1, 'celery': 1, 'tealium': 1, 'gallery': 1, 'opengl': 1, 'rust': 1, 'adobe_robohelp': 1, 'storyboard': 1, 'eval': 1, 'oracle_commerce': 1, 'prospector': 1, 'richfaces': 1})\n",
      "tfidf model\n",
      "0.542655548428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.conda/envs/ANACONDA_ENV/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.68      0.72       284\n",
      "          1       0.38      0.66      0.48       239\n",
      "          3       0.71      0.66      0.69       269\n",
      "          4       0.44      0.74      0.55       273\n",
      "          5       0.65      0.50      0.57       231\n",
      "          6       0.00      0.00      0.00       263\n",
      "\n",
      "avg / total       0.49      0.54      0.50      1559\n",
      "\n",
      "SVM + tfidf model\n",
      "0.565105837075\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.68      0.73       284\n",
      "          1       0.44      0.56      0.49       239\n",
      "          3       0.71      0.62      0.66       269\n",
      "          4       0.53      0.38      0.44       273\n",
      "          5       0.68      0.50      0.58       231\n",
      "          6       0.42      0.64      0.51       263\n",
      "\n",
      "avg / total       0.60      0.57      0.57      1559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y, index_to_field, field_to_index = get_data('/home/fun/Atos/new_Steeve_data/CareerBuilder/can/', limit=1299)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
    "print(\"Training data length: {}, Test data length: {}\".format(len(train_X), len(test_X)))\n",
    "tfidf_score, words = get_tfidf(get_doc(train_X, train_y))\n",
    "\n",
    "_y = tfidf_predict(test_X)\n",
    "print(\"tfidf model\")\n",
    "print(metrics.accuracy_score(test_y, _y))\n",
    "print(metrics.classification_report(test_y, _y))\n",
    "\n",
    "train_X = to_feature(train_X)\n",
    "test_X = to_feature(test_X)\n",
    "\n",
    "_y = train_and_predict(train_X, test_X, train_y, test_y)\n",
    "print(\"SVM + tfidf model\")\n",
    "print(metrics.accuracy_score(test_y, _y))\n",
    "print(metrics.classification_report(test_y, _y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 新 pl filter\n",
    "\n",
    "### 單純 tfidf model\n",
    "\n",
    "* filter / no_filter: 0.7064637452986967\n",
    "* no_filter / filter: 0.9252259654889071\n",
    "\n",
    "### 考慮次數的 vec 相加\n",
    "\n",
    "* filter / no_filter: 0.636753258112\n",
    "* no_fitler / filter: 0.912078882498\n",
    "\n",
    "### 不考慮次數的 vec 相加\n",
    "\n",
    "* filter / no_filter: 0.718883932476\n",
    "* no_fitler / filter: 0.928101889893\n",
    "\n",
    "### 不考慮次數的 vec * tfidf 再相加 （錯誤版）\n",
    "\n",
    "* filter / no_filter: 0.917694393423\n",
    "* no_fitler / filter: 0.965488907149\n",
    "\n",
    "### 不考慮次數的 vec * tfidf 再相加 （正確版）因為並不會取得 label 所以用第一個 model 先預測 field 再做相乘\n",
    "\n",
    "* filter / no_filter: 0.704364558733\n",
    "* no_fitler / filter: 0.916187345933\n",
    "\n",
    "\n",
    "================================\n",
    "\n",
    "# 舊 pl filter\n",
    "\n",
    "### 單純 tfidf model\n",
    "* filter / no_filter 0.699\n",
    "* no_filter / filter 0.9227608874281019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
